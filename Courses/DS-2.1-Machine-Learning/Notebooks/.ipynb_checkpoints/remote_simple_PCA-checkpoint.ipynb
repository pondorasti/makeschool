{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/learning_objectives.png\" width=\"700\" height=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principel Component Analysis (PCA)\n",
    "\n",
    "- PCA is a well-known algorithm for Dimensionality Reduction\n",
    "\n",
    "- PCA: \n",
    "\n",
    "    - Reduces the number of features while keeping the features information \n",
    "    \n",
    "    - Removes correlations among features\n",
    "    \n",
    "    - Emphasizes variation of strong features, making the data easier to visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check in for Pre-Watching of PCA:\n",
    "\n",
    "Going forward, it is assumed that you have already watched the following videos:\n",
    "\n",
    "- What is PCA?: https://www.youtube.com/watch?v=HMOI_lkzW08 \n",
    "\n",
    "- What is a covariance matrix?: https://www.youtube.com/watch?v=0GzMcUy7ZI0\n",
    "\n",
    "- How to multiply a matrix with a vector?: https://www.youtube.com/watch?v=Awcj447pYuk \n",
    "\n",
    "Are there any questions about these videos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review matrix multiplication\n",
    "\n",
    "- Matrix `A = np.array([[2, 0], [1, 5]])` and vector `v = np.array([3, 4])` are given.\n",
    "\n",
    "- **Question:** What is the multiplication of `A` by `v`?\n",
    "\n",
    "Solve using the following methods:\n",
    "\n",
    "1. Compute it by hand\n",
    "\n",
    "1. Write a Python function to compute it (Hint: use the following function form`numpy`: `np.dot(A, v)`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6 23]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[2, 0], [1, 5]])\n",
    "v = np.array([3, 4])\n",
    "\n",
    "print(np.dot(A, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EigenValue and Eigenvector of matrix\n",
    "\n",
    "For given matrix `A`, we want to obtain a vector `v` and a scalar value `a` such that:\n",
    "\n",
    "`Av = av`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a Python function to obtain vector `v` and scalar `a` for a given matrix `A`\n",
    "\n",
    "**Hints:** \n",
    "\n",
    "- Before we find the vector and scalar, we need the eigenvalues and eigenvector of Given the same matrix `A` we used above, see how [numpy's `linalg.eig`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.eig.html) method could help you solve this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 2.]\n",
      "[[ 0.          0.9486833 ]\n",
      " [ 1.         -0.31622777]]\n"
     ]
    }
   ],
   "source": [
    "eig_value, eig_vector = np.linalg.eig(A)\n",
    "\n",
    "print(eig_value)\n",
    "print(eig_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, matrix A has two eigen-values and two eigen-vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that Av = av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 5.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiply A with its first eigen-vector\n",
    "np.dot(A, eig_vector[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 5.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiply the one eigen-vector of A with its associated eigen-vector\n",
    "eig_value[0]*eig_vector[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.8973666 , -0.63245553])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarly, multiply A with its second eigen-vector\n",
    "np.dot(A, eig_vector[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.8973666 , -0.63245553])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiply the other eigen-vector of A with its associated eigen-vector\n",
    "eig_value[1]*eig_vector[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Are the countries in great UK different in terms of food?\n",
    "\n",
    "- In the table is the average consumption of 17 types of food in grams per person per week for every country in the UK\n",
    "\n",
    "- It would be great if we can visually represent diffrence among UK countries based on the food they eat \n",
    "\n",
    "<img src=\"Images/pca_UK.png\" width=\"800\" height=\"800\">\n",
    "\n",
    "- **Question**:\n",
    "\n",
    " - Which country is different from the the others? Any idea or reasoning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do it together: Write a code that obtains the principle components from 17 types of food in UK\n",
    "\n",
    "- We use two principle components as an example to see them visually, but we can pick 3 or more principle components also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 375   57  245 1472  105   54  193  147 1102  720  253  685  488  198\n",
      "   360 1374  156]\n",
      " [ 135   47  267 1494   66   41  209   93  674 1033  143  586  355  187\n",
      "   334 1506  139]\n",
      " [ 458   53  242 1462  103   62  184  122  957  566  171  750  418  220\n",
      "   337 1572  147]\n",
      " [ 475   73  227 1582  103   64  235  160 1137  874  265  803  570  203\n",
      "   365 1256  175]]\n",
      "[[-144.99315218   -2.53299944]\n",
      " [ 477.39163882  -58.90186182]\n",
      " [ -91.869339    286.08178613]\n",
      " [-240.52914764 -224.64692488]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df = pd.read_excel('pca_uk.xlsx')\n",
    "\n",
    "X = np.array([df[i].values for i in df.columns if i != 'Features'])\n",
    "\n",
    "print(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit_transform(X)\n",
    "\n",
    "# Principle components of 17 features:\n",
    "print(X_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets visualize the principle components\n",
    "\n",
    "for k, (i,j) in enumerate(zip(X_r[:, 0], X_r[:, 1])):\n",
    "    plt.scatter(i, j)\n",
    "    plt.text(i+0.3, j+0.3, df.columns[:-1][k])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: Ireland is different from other three countries in UK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many principle components we should have?\n",
    "\n",
    "- How much of the dataset information is preserved in the components?\n",
    "\n",
    "Hint: use `pca.explained_variance_ratio_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-144.99315218   -2.53299944]\n",
      " [ 477.39163882  -58.90186182]\n",
      " [ -91.869339    286.08178613]\n",
      " [-240.52914764 -224.64692488]]\n",
      "[105073.34576714  45261.62487597]\n",
      "[0.67444346 0.29052475]\n",
      "[0.67444346 0.96496821]\n"
     ]
    }
   ],
   "source": [
    "# PCA computation by sklearn\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit_transform(X)\n",
    "print(X_r)\n",
    "print(pca.explained_variance_)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the correlation of the principle components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of PCA Component:\n",
      "(0.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "print('Correlation of PCA Component:')\n",
    "print(scipy.stats.pearsonr(X_r[:, 0], X_r[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets write our own function to obtain principle components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity: PCA Steps\n",
    "\n",
    "Follow the steps here and write a function that computes the principle component for dataset we watched in YouTube.\n",
    "\n",
    "https://www.youtube.com/watch?v=0GzMcUy7ZI0 \n",
    "\n",
    "Steps: \n",
    "\n",
    "1- Subtract column mean from feature matrix -> call the name of this new matrix as centered matrix\n",
    "\n",
    "2- Calculate the covariance of centered matrix\n",
    "\n",
    "3- Calculate the eigenvalue and eigenvector of covariance matrix. Do arange eigevalue in decresing order \n",
    "\n",
    "4- Multiply the centered matrix with the top K (for example, two) eigenvector with the covariance matrix \n",
    "\n",
    "5- Compare the result of custom function with PCA in `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.65392786 -0.2775295 ]\n",
      " [-0.84584087  0.31153366]\n",
      " [ 0.55130929  0.09250983]\n",
      " [ 1.94845944 -0.126514  ]]\n",
      "[2.5171201  0.06621324]\n",
      "[0.97436907 0.02563093]\n",
      "[0.97436907 1.        ]\n",
      "Correlation of PCA Component:\n",
      "(2.7194799110210384e-16, 1.0)\n",
      "[[0.         0.         0.        ]\n",
      " [0.         1.66666667 1.16666667]\n",
      " [0.         1.16666667 0.91666667]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.65392786, -0.2775295 ],\n",
       "       [ 0.84584087,  0.31153366],\n",
       "       [-0.55130929,  0.09250983],\n",
       "       [-1.94845944, -0.126514  ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy\n",
    "\n",
    "# PCA computation by sklearn\n",
    "\n",
    "X = np.array([[1, 1, 1], [1, 2, 1], [1, 3, 2], [1, 4, 3]])\n",
    "# print(X)\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit_transform(X)\n",
    "print(X_r)\n",
    "print(pca.explained_variance_)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.cumsum())\n",
    "\n",
    "print('Correlation of PCA Component:')\n",
    "print(scipy.stats.pearsonr(X_r[:, 0], X_r[:, 1]))\n",
    "\n",
    "\n",
    "# Our function to compare \n",
    "def PCA_calculation(data, n_comp=2):\n",
    "    M = np.mean(data, axis=0)\n",
    "    # center columns by subtracting column means\n",
    "    C =  data - M\n",
    "    # calculate covariance matrix of centered matrix\n",
    "    V = np.cov(C.T)\n",
    "    print(V)\n",
    "    # eigen decomposition of covariance matrix\n",
    "    eig_value, eig_vector = np.linalg.eig(V)\n",
    "    # sort eigenvalue in decreasing order\n",
    "    idx = np.argsort(eig_value)[::-1] \n",
    "    idx_n_comp = idx[:n_comp]\n",
    "    # eigenvectors according to top n_comp largest\n",
    "    eig_vector = eig_vector[:, idx_n_comp]\n",
    "    P = np.dot(C, eig_vector)\n",
    "    return P\n",
    "\n",
    "\n",
    "PCA_calculation(X, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: Is PCA Supervised or Unsupervised?\n",
    "\n",
    "- Did we use any label to do dimensionality reduction? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Apply Principle to Boston housing features and then train the linear regression model \n",
    "\n",
    "- Basically, we remove correlation among features with PCA\n",
    "\n",
    "- We do not need to do feature data scaling (normalization) when we do PCA for features, because \n",
    "\n",
    "- Report the R-squared and MSE for a system with PCA+Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "\n",
    "- PCA is a mathematical technique to reduce redundancy in data, and is an algorithm for Dimensionality Reduction\n",
    "\n",
    "- PCA emphasizes variation and strong patterns, making the data easier to visualize\n",
    "\n",
    "- We use eigenvectors and eigenvalues to obtain the principle component (our new features) in lower dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources:\n",
    "\n",
    "-  http://setosa.io/ev/principal-component-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.65392786 -0.2775295 ]\n",
      " [ 0.84584087  0.31153366]\n",
      " [-0.55130929  0.09250983]\n",
      " [-1.94845944 -0.126514  ]]\n"
     ]
    }
   ],
   "source": [
    "def PCA_custom(data, dims_rescaled_data=2):\n",
    "    \"\"\"\n",
    "    returns: data transformed in 2 dims/columns + regenerated original data\n",
    "    pass in: data as 2D NumPy array\n",
    "    \"\"\"\n",
    "    # mean center the data\n",
    "    data = data - np.mean(data, axis=0)\n",
    "    # calculate the covariance matrix\n",
    "    R = np.cov(data, rowvar=False)\n",
    "    # calculate eigenvectors & eigenvalues of the covariance matrix\n",
    "    # use 'eigh' rather than 'eig' since R is symmetric,\n",
    "    # the performance gain is substantial\n",
    "    evals, evecs = np.linalg.eig(R)\n",
    "    # sort eigenvalue in decreasing order\n",
    "    idx = np.argsort(evals)[::-1]\n",
    "    evecs = evecs[:, idx]\n",
    "    # sort eigenvectors according to same index\n",
    "    evals = evals[idx]\n",
    "    # select the first n eigenvectors (n is desired dimension\n",
    "    # of rescaled data array, or dims_rescaled_data)\n",
    "    evecs = evecs[:, :dims_rescaled_data]\n",
    "    # carry out the transformation on the data using eigenvectors\n",
    "    # and return the re-scaled data, eigenvalues, and eigenvectors\n",
    "    return np.dot(evecs.T, data.T).T\n",
    "\n",
    "\n",
    "print(PCA_custom(X, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
