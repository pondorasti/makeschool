## Multilayer Perceptrons

### Topics
- Neural network architectures
- Multilayer perceptrons (aka feed-forward neural networks), calculating output
- Training multilayer perceptrons with backpropagation, gradient descent

### Resources
- Read Mark Humphry’s notes on [multi-layer neural networks] and the [backpropagation learning algorithm]
- Read Andrew Trask’s articles on building a neural network in Python – [part 1: optimization][Trask Neural Network part 1] and [part 2: gradient descent][Trask Neural Network part 2] – Pay close attention to the diagrams in part 2 to gain an intuition for gradient descent
- Watch Alexander Ihler’s videos on [neural networks], [backpropagation training], and [gradient descent]
- Read the Asimov Institute’s beautiful article on architectures, [The Neural Network Zoo]
- Read Alexei Borissov’s notes on [multilayer perceptrons] and follow the backpropagation weight update example (slides 16-27)


[multi-layer neural networks]: http://computing.dcu.ie/~humphrys/Notes/Neural/multi.neural.html
[backpropagation learning algorithm]: http://computing.dcu.ie/~humphrys/Notes/Neural/backprop.html
[Trask neural network part 1]: http://iamtrask.github.io/2015/07/12/basic-python-network/
[Trask neural network part 2]: http://iamtrask.github.io/2015/07/27/python-network-part2/
[neural networks]: https://www.youtube.com/watch?v=bH6VnezBZfI
[backpropagation training]: https://www.youtube.com/watch?v=6RUwfKNdaV0
[gradient descent]: https://www.youtube.com/watch?v=WnqQrPNYz5Q
[The Neural Network Zoo]: http://www.asimovinstitute.org/neural-network-zoo/
[multilayer perceptrons]: http://aass.oru.se/~lilien/ml/seminars/2007_03_12a-Borissov-MLP_1st_Order_Learning.pdf
