{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Classifier Model Performance Evaluation\n",
    "\n",
    "The material for evaluting a classifier here are applied to all classifiers\n",
    "\n",
    "We focused our concentration to Logistic Regression\n",
    "\n",
    "Read this to undestand what is Logistic Regression: https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Obtain confusion matrix, accuracy, precision, recall for pima Diabetes dataset\n",
    "\n",
    "Steps:\n",
    "\n",
    "1- Load the dataset: `pd.read_csv('diabetes.csv')`\n",
    "\n",
    "2- Use these features: `feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age']`\n",
    "\n",
    "3- split the data to train and test: `X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)`\n",
    "\n",
    "4- Instantiate logistic regressiuon model\n",
    "\n",
    "5- Obtain the statistics of `y_test`\n",
    "\n",
    "6- Obtain the confuction matrix\n",
    "\n",
    "https://www.ritchieng.com/machine-learning-evaluate-classification-model/\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic terminology\n",
    "\n",
    "True Positives (TP): we correctly predicted that they do have diabetes: 15\n",
    "\n",
    "True Negatives (TN): we correctly predicted that they don't have diabetes: 118\n",
    "\n",
    "False Positives (FP): we incorrectly predicted that they do have diabetes (a \"Type I error\"): 12\n",
    "\n",
    "False Negatives (FN): we incorrectly predicted that they don't have diabetes (a \"Type II error\"): 47\n",
    "\n",
    "<img src=\"Images/confusion_matrix.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is accuracy, recall and precision?\n",
    "\n",
    "Accuracy: overall, how often is the classifier correct? -> $accuracy = \\frac {TP + TN}{TP+TN+FP+FN}$\n",
    "\n",
    "Classification error: overall, how ofthen is the classifier incorrect? -> $error = 1- accuracy = \\frac {FP + FN}{TP + TN + FP + FN}$\n",
    "\n",
    "Recall: when the actual value is positive, how ofthen is the prediction correct? -> $recall = \\frac {TP}{TP + FN}$\n",
    "\n",
    "Precision: When a positive value is predicted, how often is the prediction correct? -> $precision = \\frac {TP}{TP + FP}$\n",
    "\n",
    "Specificity: When the actual value is negative, how often is the prediction correct? -> $Specificity = \\frac {TN}{TN + FP}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
      "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
      "      dtype='object')\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pima = pd.read_csv('diabetes.csv')\n",
    "print(pima.columns)\n",
    "print(pima.head())\n",
    "\n",
    "feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age']\n",
    "\n",
    "X = pima[feature_cols]\n",
    "# print(X)\n",
    "# y is a vector, hence we use dot to access 'label'\n",
    "y = pima['Outcome']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The difference between `.predict()` and `.predict_proba` for a classifier\n",
    "\n",
    "Apply these two methods to Pima Indian Diabetes dataset\n",
    "\n",
    "https://www.ritchieng.com/machine-learning-evaluate-classification-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
